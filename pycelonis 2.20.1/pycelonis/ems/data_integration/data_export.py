"""Module to interact with data exports.

This module contains class to interact with a data export request in EMS data integration.

Typical usage example:`

```python
# Export data directly as data frame:
df = data_model.export_data_frame(
    query
)

# Export data to CSV files
data_export = data_model.create_data_export(
    query,
    ExportType.CSV,
)
data_export.wait_for_execution()

for (
    i,
    chunk,
) in enumerate(
    data_export.get_chunks()
):
    with open(
        f"FILE_PATH_{i}.csv",
        "wb",
    ) as f:
        f.write(
            chunk.read()
        )
```
"""

import io
import logging
import typing
import uuid

from pycelonis.config import Config
from pycelonis.errors import PyCelonisDataExportFailedError, PyCelonisDataExportRunningError
from pycelonis.service.integration.service import (
    DataExportStatusResponse,
    ExportStatus,
    IntegrationService,
    ProxyDataExportStatusResponseV2,
    ProxyExportStatusV2,
)

from pycelonis.utils.polling import poll
from pycelonis_core.client.client import Client

try:
    from pydantic.v1 import Field  # type: ignore
except ImportError:
    from pydantic import Field  # type: ignore


logger = logging.getLogger(__name__)


class DataExport(DataExportStatusResponse):
    """Data export object to interact with data export specific data integration endpoints."""

    client: Client = Field(..., exclude=True)
    id: str
    """Id of data export."""
    data_model_id: str
    """Id of data model where data export is located."""

    @classmethod
    def from_transport(
        cls,
        client: Client,
        data_model_id: str,
        data_export_transport: DataExportStatusResponse,
    ) -> "DataExport":
        """Creates high-level data export object from given DataExportStatusResponse.

        Args:
            client: Client to use to make API calls for given data pool.
            data_model_id: Id of data model where data export is located.
            data_export_transport: DataExportStatusResponse object containing properties of data export.

        Returns:
            A DataExport object with properties from transport and given client.
        """
        return cls(client=client, data_model_id=data_model_id, **data_export_transport.dict())

    ############################################################
    # Chunk
    ############################################################
    def get_chunks(self) -> typing.Generator[io.BytesIO, None, None]:
        """Yields exported chunks.

        Yields:
            Byte chunks of exported data.

        Raises:
            PyCelonisDataExportRunningError: Raised in case export is still in progress.
            PyCelonisDataExportFailedError: Raised in case export failed.
        """
        logger.info("Export result chunks for data export with id '%s'", self.id)

        data_export_status = self._get_status()
        if data_export_status.export_status == ExportStatus.RUNNING:
            raise PyCelonisDataExportRunningError()

        if data_export_status.export_status != ExportStatus.DONE:
            raise PyCelonisDataExportFailedError(data_export_status.export_status, data_export_status.message)

        if data_export_status.export_chunks:
            for i in range(data_export_status.export_chunks):
                yield self._get_chunk_result(i)
        else:
            yield self._get_result()

    def wait_for_execution(self) -> None:
        """Waits until data export execution is done.

        Examples:
            Manually run data export and wait for it to finish:
            ```python
            data_export = data_model.create_data_export(
                query=query,
                export_type=ExportType.PARQUET,
            )
            data_export.wait_for_execution()
            chunks = data_export.get_chunks()

            for chunk in chunks:
                with open(
                    f"<file_name>.parquet",
                    "wb",
                ) as f:
                    f.write(
                        chunk.read()
                    )
            ```
        """

        def is_done(data_export_status: DataExportStatusResponse) -> bool:
            """Returns whether data export is still running."""
            return data_export_status.export_status != ExportStatus.RUNNING

        def format_status(data_export_status: DataExportStatusResponse) -> str:
            """Returns formatted data export status containing status and message."""
            formatted_export_status = "Status:"

            if data_export_status.export_status:
                formatted_export_status += f" {data_export_status.export_status}"
            if data_export_status.message:
                formatted_export_status += f" {data_export_status.message}"

            return formatted_export_status

        logger.info("Wait for execution of data export with id '%s'", self.id)
        poll(
            target=self._get_status,
            wait_for=is_done,
            message=format_status,
            sleep=Config.POLLING_WAIT_SECONDS,
        )

    def _get_chunk_result(self, chunk_id: int) -> io.BytesIO:
        """Gets export result from chunked endpoint. Also works if export data is only one chunk (chunk_id=0)."""
        return IntegrationService.get_api_v1_compute_data_model_id_export_export_id_chunk_id_result(
            self.client, self.data_model_id, self.id, str(chunk_id)
        )

    def _get_result(self) -> io.BytesIO:
        """Gets export result from non-chunked endpoint. Endpoint only works if exported data is only one chunk."""
        return IntegrationService.get_api_v1_compute_data_model_id_export_export_id_result(
            self.client, self.data_model_id, self.id
        )

    def _get_status(self) -> DataExportStatusResponse:
        return IntegrationService.get_api_v1_compute_data_model_id_export_export_id(
            self.client, self.data_model_id, self.id
        )

    def __main_attributes__(self) -> typing.Optional[typing.List[str]]:
        return ["id", "export_status", "message"]


class DataExportV2(ProxyDataExportStatusResponseV2):
    """Data export object to interact with version 2 of data export specific data integration endpoints."""

    client: Client = Field(..., exclude=True)
    id: uuid.UUID
    """Id of data export."""
    data_model_id: str
    """Id of data model where data export is located."""

    @classmethod
    def from_transport(
        cls,
        client: Client,
        data_model_id: str,
        data_export_transport: ProxyDataExportStatusResponseV2,
    ) -> "DataExportV2":
        """Creates high-level data export object from given DataExportStatusResponse.

        Args:
            client: Client to use to make API calls for given data pool.
            data_model_id: Id of data model where data export is located.
            data_export_transport: ProxyDataExportStatusResponseV2 object containing properties of data export.

        Returns:
            A DataExport object with properties from transport and given client.
        """
        return cls(client=client, data_model_id=data_model_id, **data_export_transport.dict())

    ############################################################
    # Chunk
    ############################################################
    def get_chunks(self) -> typing.Generator[io.BytesIO, None, None]:
        """Yields exported chunks.

        Yields:
            Byte chunks of exported data.

        """
        logger.info("Export result chunks for data export with id '%s'", str(self.id))

        data_export_status = self._get_status()
        if data_export_status.export_status == ProxyExportStatusV2.RUNNING:
            raise PyCelonisDataExportRunningError()

        if data_export_status.export_status != ProxyExportStatusV2.DONE:
            raise PyCelonisDataExportFailedError(data_export_status.export_status, data_export_status.messages)

        for chunk in data_export_status.exported_chunks:  # type: ignore
            yield self._get_chunk_result(chunk.id)  # type: ignore

    def wait_for_execution(self) -> None:
        """Waits until data export execution is done.

        Examples:
            Manually run data export and wait for it to finish to get all chunks:
            ```python
            data_export = data_model.create_data_export(
                query=query,
                export_type=ExportType.PARQUET,
            )
            data_export.wait_for_execution()
            chunks = data_export.get_chunks()

            for chunk in chunks:
                with open(
                    f"<file_name>.parquet",
                    "wb",
                ) as f:
                    f.write(
                        chunk.read()
                    )
            ```
        """

        def is_done(data_export_status: ProxyDataExportStatusResponseV2) -> bool:
            """Returns whether data export is still running."""
            return data_export_status.export_status != ProxyExportStatusV2.RUNNING

        def format_status(data_export_status: ProxyDataExportStatusResponseV2) -> str:
            """Returns formatted data export status containing status and message."""
            formatted_export_status = "Status:"

            if data_export_status.export_status:
                formatted_export_status += f" {data_export_status.export_status}"
            if data_export_status.messages:
                for message in data_export_status.messages:
                    formatted_export_status += f" {message}"

            return formatted_export_status

        logger.info("Wait for execution of data export with id '%s'", str(self.id))
        poll(
            target=self._get_status,
            wait_for=is_done,
            message=format_status,
            sleep=Config.POLLING_WAIT_SECONDS,
        )

    def _get_chunk_result(self, chunk_id: int) -> io.BytesIO:
        """Gets export result from chunked endpoint. Also works if export data is only one chunk (chunk_id=0)."""
        return IntegrationService.get_api_external_compute_data_models_data_model_id_query_exports_export_id_chunks_chunk_id(
            self.client, self.data_model_id, str(self.id), chunk_id
        )

    def _get_status(self) -> ProxyDataExportStatusResponseV2:
        return IntegrationService.get_api_external_compute_data_models_data_model_id_query_exports_export_id(
            self.client, self.data_model_id, str(self.id)
        )

    def __main_attributes__(self) -> typing.Optional[typing.List[str]]:
        return ["id", "export_status", "messages"]
